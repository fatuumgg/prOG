## **Финальный проект**

Разработать систему управления контекстом диалога с LLM, которая обеспечивает долгосрочную память и обрезание истории сообщений при превышении лимита.

  

### **1. Минимальный функционал:**

- **Хранение структурированной истории**: хранение реплик пользователя (`user`) и ассистента (`assistant`)

- **Ведение подсчёта токенов**: при помощи токенизатора

- **Обрезание истории**: при превышении лимита контекста (суммарно по токенам пользователя и ассистента) система должна забывать наиболее старые части диалога (удалять или не подавать в качестве контекста)

- **Тестирование с заглушкой**: возможность работы без реальной LLM (mock-режим)

  

### **2. Расширенный функционал:**

- **A. Суммаризация истории**:

- Автоматическое создание краткого содержания старых частей диалога. Пусть ассистент не помнит деталей старых обсуждений, зато знает, что в целом обсуждалось. (требуется ллм)

- Замена длинных фрагментов на суммаризированные версии

  

- **B. RAG-интеграция (работа с документами)**:

- Загрузка и индексация внешних документов (например, книги в формате TXT/PDF)

- Семантический поиск по документам при релевантных запросах

- Включение найденных фрагментов в контекст диалога

  

- **C. Персистентная память о пользователе** (по аналогии с ChatGPT):

- Обнаружение и хранение ключевых фактов о пользователе

- Автоматическое извлечение и обновление информации

- Использование этой памяти как контекст в других диалоговых сессиях